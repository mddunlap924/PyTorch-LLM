{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "- Author: Myles Dunlap\n",
    "\n",
    "\n",
    "This notebook is used to train a model using a single configuration file. The steps in this notebook are used in the Python script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the path for the custom modules\n",
    "path_custom_modules = '../'\n",
    "\n",
    "# Path to the YAML config. file\n",
    "path_cfg = {'base_dir': '../cfgs',\n",
    "            'filename': 'train-0.yaml'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "import inspect\n",
    "\n",
    "# Append Path to Custom Modules\n",
    "sys.path.append(path_custom_modules)\n",
    "\n",
    "# Custom Modules\n",
    "from src.models import llm_multiclass\n",
    "from src.utils import (RecursiveNamespace,\n",
    "                       seed_everything,\n",
    "                       load_cfg,\n",
    "                       RunIDs)\n",
    "from src.dataloading.load_data import LoadData\n",
    "from src.dataloading.stratify import StratifyData\n",
    "from src.dataloading.preprocess import PreprocessData\n",
    "from src.dataloading.load_datasets import (TrainDataset,\n",
    "                                           CustomTextCollator,\n",
    "                                           )\n",
    "\n",
    "# Allow HF tokenizer parallelism\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'True'\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "CFG = load_cfg(base_dir=Path(path_cfg['base_dir']),\n",
    "               filename=path_cfg['filename'])\n",
    "\n",
    "# Set random seed on everything\n",
    "seed_everything(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group ID: f96d4ac2\n",
      "ID for Testing Fold #1: c35b8d3c\n",
      "\tFull/Entire ID: f96d4ac2-c35b8d3c\n",
      "ID for Testing Fold #2: 2757f8cb\n",
      "\tFull/Entire ID: f96d4ac2-2757f8cb\n",
      "ID for Testing Fold #3: 8fceedf3\n",
      "\tFull/Entire ID: f96d4ac2-8fceedf3\n",
      "ID for Testing Fold #4: eef8284a\n",
      "\tFull/Entire ID: f96d4ac2-eef8284a\n",
      "ID for Testing Fold #5: 2a0391f9\n",
      "\tFull/Entire ID: f96d4ac2-2a0391f9\n"
     ]
    }
   ],
   "source": [
    "# Group ID and ID for each fold tested\n",
    "run_ids = RunIDs(test_folds=CFG.cv.val_folds,\n",
    "                 num_folds=CFG.cv.num_folds)\n",
    "run_ids.generate_run_ids()\n",
    "\n",
    "# Print the group id and ids for each fold\n",
    "print(f'Group ID: {run_ids.group_id}')\n",
    "for fold_num in CFG.cv.val_folds:\n",
    "    fold_id = getattr(run_ids.folds_id,\n",
    "                      f'fold{fold_num}').run_id\n",
    "    entire_id = f'{run_ids.group_id}-{fold_id}' \n",
    "    print((f'ID for Testing Fold #{fold_num}: '\n",
    "           f'{fold_id}\\n\\tFull/Entire ID: {entire_id}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from Disk\n",
    "load_data_file = LoadData(base_dir=CFG.paths.data.base_dir)\n",
    "if CFG.debug:\n",
    "    data = load_data_file.load(filename=CFG.paths.data.debug_data)\n",
    "else:\n",
    "    data = load_data_file.load(filename=CFG.paths.data.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>State</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Product</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Summer of XX/XX/2018 I was denied a mortga...</td>\n",
       "      <td>IL</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are many mistakes appear in my report wi...</td>\n",
       "      <td>VA</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are many mistakes appear in my report wi...</td>\n",
       "      <td>TX</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There are many mistakes appear in my report wi...</td>\n",
       "      <td>TX</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are many mistakes appear in my report wi...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative State  \\\n",
       "0  The Summer of XX/XX/2018 I was denied a mortga...    IL   \n",
       "1  There are many mistakes appear in my report wi...    VA   \n",
       "2  There are many mistakes appear in my report wi...    TX   \n",
       "3  There are many mistakes appear in my report wi...    TX   \n",
       "4  There are many mistakes appear in my report wi...    CA   \n",
       "\n",
       "  Company response to consumer  \\\n",
       "0      Closed with explanation   \n",
       "1      Closed with explanation   \n",
       "2      Closed with explanation   \n",
       "3      Closed with explanation   \n",
       "4      Closed with explanation   \n",
       "\n",
       "                                             Product  fold  \n",
       "0  Credit reporting, credit repair services, or o...     1  \n",
       "1  Credit reporting, credit repair services, or o...     1  \n",
       "2  Credit reporting, credit repair services, or o...     1  \n",
       "3  Credit reporting, credit repair services, or o...     1  \n",
       "4  Credit reporting, credit repair services, or o...     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of a Product for Each Fold\n",
      "Notice how the quantities are evenly distributed across folds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Product                  fold\n",
       "Bank account or service  1       2953\n",
       "                         2       2953\n",
       "                         3       2954\n",
       "                         4       2953\n",
       "                         5       2953\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stratify the Data\n",
    "data = (StratifyData(technique=CFG.stratify.technique,\n",
    "                     n_folds=CFG.cv.num_folds,\n",
    "                     target=CFG.data_info.target)\n",
    "            .stratify(df=data))\n",
    "cols = CFG.data_info.source_fields + \\\n",
    "       [CFG.data_info.target, 'fold']\n",
    "display(data[cols].head(5))\n",
    "print(f'Distribution of a Product for Each Fold')\n",
    "print(f'Notice how the quantities are evenly distributed across folds')\n",
    "display(data.groupby('Product').fold.value_counts()\n",
    "        .sort_index().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_tokenizer.base_dir}/'\n",
    "                                          f'{CFG.model_tokenizer.name}')\n",
    "\n",
    "# Collator\n",
    "collator = CustomTextCollator(tokenizer=tokenizer,\n",
    "                              max_sequence_len=CFG.tokenizer.max_length,\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start looping over folds here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Number of Instances: 305,739\n",
      "Validation Number of Instances: 76,435\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Train a model for each validation fold\n",
    "fold_num = CFG.cv.val_folds[0]\n",
    "\n",
    "# Split Data into Training and Validation\n",
    "df_train = data.copy()[data.fold != fold_num].reset_index(drop=True)\n",
    "df_val = data.copy()[data.fold == fold_num].reset_index(drop=True)\n",
    "print(f'Train Number of Instances: {len(df_train):,}')\n",
    "print(f'Validation Number of Instances: {len(df_val):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Target\n",
    "\n",
    "Convert the text target into a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Encoders\n",
    "encoders = {}\n",
    "for technique in CFG.preprocessing.apply_techniques:\n",
    "    fields = getattr(CFG.preprocessing, technique).fields\n",
    "    for col in fields:\n",
    "        enc = PreprocessData(y=df_train[col].values,\n",
    "                             technique=technique)\n",
    "        encoders[col] = {'encoder': enc.encoder,\n",
    "                         'technique': technique}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all mix-data type fields\n",
    "\n",
    "In this [blob post by Chris McCormick](https://mccormickml.com/2021/06/29/combining-categorical-numerical-features-with-bert/) an interesting approach was taken to combine mixed data types which was to convert all categorical and numerical into the text feed into the LLM. This repository will try this technique ingle string that will be processed by the LLM. \n",
    "\n",
    "Another approach is only pass the unstructured text into the LLM, take its last layer output and combine with the other mixed data types into a dense layer. This type of approach seems more common and an example can be found on [Google Colab here](https://colab.research.google.com/drive/1F7COnwHqcLDPg_SS-oFgW3c2GPDWnS5Y#scrollTo=BAQFbN-wBpoz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Training Instances: 305,739\n",
      "Batch Size: 4\n",
      "305,739 / 4 = 76,435\n",
      "Train DataLoader # of Iters: 76,435\n",
      "Val. DataLoader # of Iters: 19,109\n"
     ]
    }
   ],
   "source": [
    "# Train Dataset and Dataloader\n",
    "train_dataset = TrainDataset(df=df_train,\n",
    "                             tok=tokenizer,\n",
    "                             tok_cfg=CFG.tokenizer,\n",
    "                             X_cols=CFG.data_info.source_fields,\n",
    "                             label=CFG.data_info.target,\n",
    "                             encoder=encoders[CFG.data_info.target]['encoder'])\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              collate_fn=collator,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers,\n",
    "                              pin_memory=True)\n",
    "\n",
    "# Validation Dataset and Dataloader\n",
    "val_dataset = TrainDataset(df=df_val,\n",
    "                           tok=tokenizer,\n",
    "                           tok_cfg=CFG.tokenizer,\n",
    "                           X_cols=CFG.data_info.source_fields,\n",
    "                           label=CFG.data_info.target,\n",
    "                           encoder=encoders[CFG.data_info.target]['encoder'])\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=CFG.batch_size,\n",
    "                            collate_fn=collator,\n",
    "                            shuffle=True,\n",
    "                            num_workers=CFG.num_workers,\n",
    "                            pin_memory=True)\n",
    "\n",
    "print(f'# of Training Instances: {len(df_train):,}')\n",
    "print(f'Batch Size: {CFG.batch_size}')\n",
    "print(f'{len(df_train):,} / {CFG.batch_size:,} = {len(train_dataloader):,}')\n",
    "print(f'Train DataLoader # of Iters: {len(train_dataloader):,}')\n",
    "print(f'Val. DataLoader # of Iters: {len(val_dataloader):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: torch.Size([4, 512])\n",
      "1: torch.Size([4, 428])\n",
      "2: torch.Size([4, 334])\n",
      "3: torch.Size([4, 512])\n",
      "4: torch.Size([4, 512])\n",
      "5: torch.Size([4, 512])\n",
      "6: torch.Size([4, 512])\n",
      "7: torch.Size([4, 169])\n",
      "8: torch.Size([4, 445])\n",
      "9: torch.Size([4, 125])\n",
      "10: torch.Size([4, 257])\n"
     ]
    }
   ],
   "source": [
    "for i, inputs in enumerate(train_dataloader):\n",
    "    if i > 10:\n",
    "        break\n",
    "    else:\n",
    "        shape = inputs['input_ids'].shape\n",
    "    print(f'{i}: {shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_dataset))\n",
    "inputs = a['inputs']\n",
    "labels = a['labels']\n",
    "collator({'label', labels})\n",
    "\n",
    "# print(type(inputs))\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for step, (a, b) in enumerate(train_dataloader):\n",
    "    print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, BertForPreTraining, AutoModelForMaskedLM, BertForMaskedLM\n",
    "model_cfg = AutoConfig.from_pretrained(Path(CFG.model_tokenizer.base_dir) / CFG.model_tokenizer.name)\n",
    "model = BertForMaskedLM.from_pretrained(Path(CFG.model_tokenizer.base_dir) / CFG.model_tokenizer.name,\n",
    "                                  config=model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(18):\n",
    "#     a, b = next(iter(train_dataset), i)\n",
    "#     print(a['input_ids'].shape)\n",
    "#     print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_dataset))\n",
    "\n",
    "# # Train a model for each validation fold\n",
    "# for fold_num in CFG.stratify.val_folds:\n",
    "#     print(f'Starting Training for Fold {fold_num}')\n",
    "    \n",
    "#     # Training Module\n",
    "    \n",
    "#     # Inference Module\n",
    "    \n",
    "#     print(f'\\tFinished Training for Fold {fold_num}')\n",
    "# print('Training and Validation Completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
